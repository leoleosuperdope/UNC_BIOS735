---
title: "HW 7 - Numerical Integration"
author: "Leo Li (PID: 730031954)"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(statmod)
library(data.table)
library(optimx)
library(numDeriv)
```

# Maximization of poisson GLMM from lecture

Now that we have discussed several approaches for numerical integration, lets now maximize the model given in lecture.  You may choose any maximization approach, as well as any numerical integration procedure from lecture, to obtain the MLE's for $\boldsymbol{\beta}$ and $\sigma_{\gamma}^2$.  

Hint: You should evaluate a number of intervals/nodes, decreasing the convergence threshold, etc and evaluate its impact before reporting your final result. We have shown how to perform, for example, AGQ and IS to obtain the likelihood pertaining to the first subject from class. 

```{r}
## Solution: place relevant helper functions pertaining to integration here
h <- function(y, theta, gammai, log=F){
    lambda <- exp(theta[1] + theta[2]*c(1:5) + gammai)
    val <- prod(dpois(x = y, lambda = lambda)) * dnorm(x = gammai, mean = 0, sd = sqrt(theta[3]))
    if(log==F){
      return(val)
    } else{
        return(log(val))
      }
}

inner <- function(theta, node, y, pm, sd_hess, log=F){
  val  <- rep(NA, length(node))
  for(i in seq(length(node))){
    val[i] <- h(y, theta, gammai = node[i])/dnorm(node[i], pm, sd_hess)
  }
  if(log==F){
    return(val)
  } else{
    return(log(val))
    }
}
## End Solution

## Solution: place relevant helper functions pertaining to maximization here (likelihood etc)
log.likelihood.i <- function(theta, y,s=s, w=w){
 wt <- w/sqrt(pi)
 pm <- suppressWarnings(
    optimx(par = 0, fn = function(x, y, theta) {-h(gammai = x,y = y,theta = theta)}, y = y, theta = theta,
      method = "Nelder-Mead"))
 pm <- pm$p1
 hess_pm <-  hessian(func = h, x = pm, y = y, theta = theta, log = T)
 sd_hess <- sqrt(-1 / hess_pm)[[1]]
 t <-  s*sqrt(2*sd_hess^2) + pm
 adq <- inner(theta=theta, node=t, y=y, pm=pm, sd_hess = sd_hess)
 val <- log(sum(adq*wt))
 return(val)
}

log.likelihood <- function(theta, data, M){ 
  gh <-  gauss.quad(n = M, kind = "hermite")
  s <-  gh$nodes
  w <-  gh$weights
  val <- 0
  for (i in 1:max(alz$subject)){
    val = val + log.likelihood.i(y=data$words[data$subject == i], theta = theta, s=s, w=w)
  }
  return(val)
}
## End Solution

## Solution: place primary code for maximization here, calling functions in the above two sections
## Remember to print your primary results and use the following starting values
beta = c(1.804, 0.165)
s2gamma = 0.000225
theta = c(beta, s2gamma)
setwd("C:/Users/haoli/Desktop/735/Homework/HW7")
alz = read.delim(file = "alzheimers.txt", header = T, sep = "", dec = ".")

# selecting the value of M
for (M in 1:10){
  val <- log.likelihood(data=alz, theta = c(beta, s2gamma), M=M)
  print(paste0('M = ', M, ", log-likelihood = ", val)) 
}
  
# the calculation of log-likelihood starts to stablize after M=5
fit <- suppressWarnings(optimx(par=theta, fn = function(x, data, M)
  {-log.likelihood(theta=x, data= data, M=M)}, method="Nelder-Mead", data = alz, M=5))

# print the estimate for beta
c(fit$p1, fit$p2)

# print the estimate for s2gamma
fit$p3
```

# Plot

Now, plot the fitted line from the fitted GLMM on the spaghetti plot from lecture

```{r}
## solution
for (i in 1:max(alz$subject)) {
    index = which(alz$subject == i)
    if (i == 1) {
      plot(alz$month[index], alz$words[index], type = 'l', ylim = range(alz$words), ylab = "Words",
        xlab = "Month", col = i)
      lines(alz$month[index], exp(fit$p1+fit$p2*(alz$month[index])), lty = 3, lwd=3)
    } else{
      lines(alz$month[index], alz$words[index], type = 'l', col = i)
    }
  }
## end solution
```